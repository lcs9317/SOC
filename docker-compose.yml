

services:
  # -------------------------------------------------------
  # 1) Zookeeper & Kafka
  # -------------------------------------------------------
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - kafka_network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"  # 내부 통신용
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,INTERNAL://:29092
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092,INTERNAL://kafka:29092
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_HEAP_OPTS=-Xmx512M -Xms512M  # 힙 메모리를 512MB로 제한
    depends_on:
      zookeeper:
        condition: service_healthy
    networks:
      - kafka_network
    healthcheck:
      test: ["CMD", "kafka-topics.sh", "--list", "--bootstrap-server", "kafka:29092"]
      interval: 30s
      timeout: 10s
      retries: 3
  
  # ----------------------------
  # 2) Zeek (공식 이미지)
  # ----------------------------
  zeek:
    image: zeek/zeek:latest         # 공식 Zeek 이미지
    container_name: zeek
    network_mode: host              # 실제 네트워크 트래픽 캡처 위해 호스트 네트워크 사용
    volumes:
      - ./zeek/logs:/opt/zeek/logs  # Zeek 로그 확인용
      - ./zeek/scripts:/opt/zeek/share/zeek/site  # Zeek 스크립트 마운트
      - ./zeek/zeek.cfg:/opt/zeek/share/zeek/zeek.cfg  # Zeek 설정 파일 마운트
    privileged: true                # 네트워크 캡처 권한
    environment:
      - ZEEK_SCRIPT_PATH=kafka-send.zeek   # 우리가 작성한 스크립트명
      - KAFKA_BOOTSTRAP=host.docker.internal:9092          # Kafka 브로커 주소
      - KAFKA_TOPIC=network-traffic
    command: ["zeek", "-C", "-i", "eth0"]          # 인터페이스 지정
    depends_on:
      - kafka


  # -------------------------------------------------------
  # 2) Logstash (Kafka -> Elasticsearch)
  # -------------------------------------------------------
  logstash:
    image: docker.elastic.co/logstash/logstash:8.17.1
    container_name: logstash
    depends_on:
      - kafka
      - elasticsearch
    volumes:
      - ./logstash/pipeline/:/usr/share/logstash/pipeline/
    ports:
      - "5044:5044"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"  # 힙 메모리를 256MB로 제한
    networks:
      - kafka_network

  # -------------------------------------------------------
  # 3) Elasticsearch & Kibana
  # -------------------------------------------------------
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.1
    container_name: elasticsearch
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g  # 힙 메모리를 1GB로 제한
    networks:
      - kafka_network
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q 'status.*green\\|status.*yellow'"]
      interval: 30s
      timeout: 10s
      retries: 3

  kibana:
    image: docker.elastic.co/kibana/kibana:8.17.1
    container_name: kibana
    depends_on:
      - elasticsearch
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - NODE_OPTIONS=--max-old-space-size=512  # Node.js 메모리 제한을 512MB로 설정
    networks:
      - kafka_network
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:5601/status | grep -q '\"state\":\"green\"'"]
      interval: 30s
      timeout: 10s
      retries: 3

  # -------------------------------------------------------
  # 4) Network Collector (Scapy -> Kafka)
  # -------------------------------------------------------
  #network-collector:
  #  build:
  #    context: ./collector
  #    dockerfile: Dockerfile
  #  container_name: network-collector
  #  networks:
  #    - kafka_network
  #  privileged: true  # scapy sniff 권한
  #  depends_on:
  #    kafka:
  #      condition: service_healthy
  #  environment:
  #    - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
  #  deploy:
  #    resources:
  #      limits:
  #        memory: 512M  # 메모리 제한을 512MB로 설정
  #  restart: on-failure:3

  # -------------------------------------------------------
  # 5) AI Model Trainer (일회성 실행)
  # -------------------------------------------------------
  trainer:
    build:
      context: ./trainer
      dockerfile: Dockerfile
    container_name: trainer
    networks:
      - kafka_network
    volumes:
      - ./datasets:/app/datasets
      - ./models:/app/models
    deploy:
      resources:
        limits:
          memory: 512M  # 메모리 제한을 512MB로 설정
    # 주로 "docker-compose run trainer" 형태로 필요시 학습
    # command: ["python", "trainer.py"]

  # -------------------------------------------------------
  # 6) AI Inference (Kafka -> Inference -> Elasticsearch)
  # -------------------------------------------------------
  ai-inference:
    build:
      context: ./inference
      dockerfile: Dockerfile
    container_name: ai-inference
    networks:
      - kafka_network
    depends_on:
      kafka:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
    volumes:
      - ./models:/app/models
    environment:
      - MODEL_TYPE=cnn
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_TOPIC=network-traffic
      - ELASTICSEARCH_HOST=elasticsearch
      - ELASTICSEARCH_PORT=9200
    deploy:
      resources:
        limits:
          memory: 512M  # 메모리 제한을 512MB로 설정

networks:
  kafka_network:
    driver: bridge
